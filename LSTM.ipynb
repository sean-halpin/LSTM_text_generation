{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOg+KvjCVjNx1GztioCAfuD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sean-halpin/LSTM_text_generation/blob/main/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXHRBgKEQigh"
      },
      "source": [
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E08_eSsHVi8-"
      },
      "source": [
        "import requests\n",
        "url = \"http://www.gutenberg.org/cache/epub/11/pg11.txt\"\n",
        "r = requests.get(url, allow_redirects=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbBfvHOFXDu1",
        "outputId": "a88637e1-53bd-458a-e5fe-20569e375d85"
      },
      "source": [
        "print(r.text.splitlines()[0])\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ï»¿Project Gutenberg's Alice's Adventures in Wonderland, by Lewis Carroll\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMGfwEMrXGEz"
      },
      "source": [
        "raw_text = r.text.lower()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vT-m7gG4XfHS"
      },
      "source": [
        "# create mapping of unique chars to integers\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-i7D7Ht-XmzC",
        "outputId": "ef2f1811-d33e-4400-851a-33048efab51b"
      },
      "source": [
        "print(char_to_int)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'\\n': 0, '\\r': 1, ' ': 2, '!': 3, '\"': 4, '#': 5, '$': 6, '%': 7, \"'\": 8, '(': 9, ')': 10, '*': 11, ',': 12, '-': 13, '.': 14, '/': 15, '0': 16, '1': 17, '2': 18, '3': 19, '4': 20, '5': 21, '6': 22, '7': 23, '8': 24, '9': 25, ':': 26, ';': 27, '?': 28, '@': 29, '[': 30, ']': 31, '_': 32, 'a': 33, 'b': 34, 'c': 35, 'd': 36, 'e': 37, 'f': 38, 'g': 39, 'h': 40, 'i': 41, 'j': 42, 'k': 43, 'l': 44, 'm': 45, 'n': 46, 'o': 47, 'p': 48, 'q': 49, 'r': 50, 's': 51, 't': 52, 'u': 53, 'v': 54, 'w': 55, 'x': 56, 'y': 57, 'z': 58, '\\ufeff': 59}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkQc77WaXrmg",
        "outputId": "97d1273e-6950-413e-e0b4-f69389b97126"
      },
      "source": [
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print(\"Total Characters: \", n_chars)\n",
        "print(\"Total Vocab: \", n_vocab)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Characters:  167516\n",
            "Total Vocab:  60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOjJVS47Y8th",
        "outputId": "cd3252e5-d4de-4c81-bee9-569e8c53a3d8"
      },
      "source": [
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "\tseq_in = raw_text[i:i + seq_length]\n",
        "\tseq_out = raw_text[i + seq_length]\n",
        "\tdataX.append([char_to_int[char] for char in seq_in])\n",
        "\tdataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print(\"Total Patterns: \", n_patterns)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Patterns:  167416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riyRFwLHY-Ly"
      },
      "source": [
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhbVxselZNpc"
      },
      "source": [
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gStJl5D3ZSF7"
      },
      "source": [
        "# define the checkpoint\n",
        "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxWaYaxoZmOa",
        "outputId": "4bd051fb-cb64-4117-fa20-39b8648c930b"
      },
      "source": [
        "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1308/1308 [==============================] - 53s 35ms/step - loss: 2.9848\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.98478, saving model to weights-improvement-01-2.9848.hdf5\n",
            "Epoch 2/20\n",
            "1308/1308 [==============================] - 46s 35ms/step - loss: 2.7882\n",
            "\n",
            "Epoch 00002: loss improved from 2.98478 to 2.78821, saving model to weights-improvement-02-2.7882.hdf5\n",
            "Epoch 3/20\n",
            "1308/1308 [==============================] - 46s 35ms/step - loss: 2.6880\n",
            "\n",
            "Epoch 00003: loss improved from 2.78821 to 2.68797, saving model to weights-improvement-03-2.6880.hdf5\n",
            "Epoch 4/20\n",
            "1308/1308 [==============================] - 46s 35ms/step - loss: 2.6000\n",
            "\n",
            "Epoch 00004: loss improved from 2.68797 to 2.59997, saving model to weights-improvement-04-2.6000.hdf5\n",
            "Epoch 5/20\n",
            "1308/1308 [==============================] - 46s 35ms/step - loss: 2.5508\n",
            "\n",
            "Epoch 00005: loss improved from 2.59997 to 2.55080, saving model to weights-improvement-05-2.5508.hdf5\n",
            "Epoch 6/20\n",
            "1308/1308 [==============================] - 46s 35ms/step - loss: 2.4963\n",
            "\n",
            "Epoch 00006: loss improved from 2.55080 to 2.49634, saving model to weights-improvement-06-2.4963.hdf5\n",
            "Epoch 7/20\n",
            "1308/1308 [==============================] - 46s 36ms/step - loss: 2.4563\n",
            "\n",
            "Epoch 00007: loss improved from 2.49634 to 2.45630, saving model to weights-improvement-07-2.4563.hdf5\n",
            "Epoch 8/20\n",
            "1308/1308 [==============================] - 46s 35ms/step - loss: 2.4111\n",
            "\n",
            "Epoch 00008: loss improved from 2.45630 to 2.41111, saving model to weights-improvement-08-2.4111.hdf5\n",
            "Epoch 9/20\n",
            "1308/1308 [==============================] - 46s 35ms/step - loss: 2.3700\n",
            "\n",
            "Epoch 00009: loss improved from 2.41111 to 2.37004, saving model to weights-improvement-09-2.3700.hdf5\n",
            "Epoch 10/20\n",
            "1308/1308 [==============================] - 46s 35ms/step - loss: 2.3326\n",
            "\n",
            "Epoch 00010: loss improved from 2.37004 to 2.33262, saving model to weights-improvement-10-2.3326.hdf5\n",
            "Epoch 11/20\n",
            "1308/1308 [==============================] - 46s 35ms/step - loss: 2.2964\n",
            "\n",
            "Epoch 00011: loss improved from 2.33262 to 2.29645, saving model to weights-improvement-11-2.2964.hdf5\n",
            "Epoch 12/20\n",
            "1308/1308 [==============================] - 46s 35ms/step - loss: 2.2629\n",
            "\n",
            "Epoch 00012: loss improved from 2.29645 to 2.26286, saving model to weights-improvement-12-2.2629.hdf5\n",
            "Epoch 13/20\n",
            "1308/1308 [==============================] - 46s 35ms/step - loss: 2.3226\n",
            "\n",
            "Epoch 00013: loss did not improve from 2.26286\n",
            "Epoch 14/20\n",
            "1308/1308 [==============================] - 46s 35ms/step - loss: 2.2983\n",
            "\n",
            "Epoch 00014: loss did not improve from 2.26286\n",
            "Epoch 15/20\n",
            "1308/1308 [==============================] - 47s 36ms/step - loss: 2.2378\n",
            "\n",
            "Epoch 00015: loss improved from 2.26286 to 2.23775, saving model to weights-improvement-15-2.2378.hdf5\n",
            "Epoch 16/20\n",
            "1308/1308 [==============================] - 46s 36ms/step - loss: 2.2098\n",
            "\n",
            "Epoch 00016: loss improved from 2.23775 to 2.20984, saving model to weights-improvement-16-2.2098.hdf5\n",
            "Epoch 17/20\n",
            "1308/1308 [==============================] - 46s 35ms/step - loss: 2.1907\n",
            "\n",
            "Epoch 00017: loss improved from 2.20984 to 2.19067, saving model to weights-improvement-17-2.1907.hdf5\n",
            "Epoch 18/20\n",
            "1308/1308 [==============================] - 46s 35ms/step - loss: 2.1764\n",
            "\n",
            "Epoch 00018: loss improved from 2.19067 to 2.17645, saving model to weights-improvement-18-2.1764.hdf5\n",
            "Epoch 19/20\n",
            "1308/1308 [==============================] - 47s 36ms/step - loss: 2.1580\n",
            "\n",
            "Epoch 00019: loss improved from 2.17645 to 2.15803, saving model to weights-improvement-19-2.1580.hdf5\n",
            "Epoch 20/20\n",
            "1308/1308 [==============================] - 47s 36ms/step - loss: 2.1398\n",
            "\n",
            "Epoch 00020: loss improved from 2.15803 to 2.13976, saving model to weights-improvement-20-2.1398.hdf5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5c90274110>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFnFEax8gjaQ",
        "outputId": "ebbfd3e0-3f41-4b62-b2d5-207d592ed50d"
      },
      "source": [
        "import sys\n",
        "# load the network weights\n",
        "filename = \"weights-improvement-11-2.2964.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "# pick a random seed\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print(\"Seed:\")\n",
        "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "# generate characters\n",
        "for i in range(1000):\n",
        "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = numpy.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "\tseq_in = [int_to_char[value] for value in pattern]\n",
        "\tsys.stdout.write(result)\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]\n",
        "print(\"\\nDone.\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed:\n",
            "\" turtles, salmon, and so on;\r\n",
            "then, when you've cleared all the jelly-fish out of the way--'\r\n",
            "\r\n",
            "'that \"\n",
            " you dan to tee to the tooee to the toier,' said the caterpillar.\n",
            "\n",
            "'the mort toin i cen to toen ' said the caterpillar an an anl aoo tooe\n",
            "that she wooee to the woeke and the tasten  the was so the tooee to the\n",
            "coone th the tooee  the woote whit toe toete to the tooee to the tooee\n",
            "ant the woite woat she woote whit the woite oo the tooee to the woiee\n",
            "tht soee an the toote  the woote whit the tooee to the tooee to the houte\n",
            "and the toree to the tooee to the tooee an the woike and the tasten \n",
            "and the tooee to the tooee to the tooee to the tooee  tha wasten an \n",
            "the woote  \n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AvPzTkogotn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}